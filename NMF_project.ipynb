{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 718)\n",
      "column:  C\n",
      "C\n",
      "type:  <class 'str'>\n",
      "column:  D\n",
      "D\n",
      "type:  <class 'str'>\n",
      "column:  D\n",
      "D\n",
      "type:  <class 'str'>\n",
      "column:  C\n",
      "C\n",
      "type:  <class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([                                        'pclass',\n",
       "                                             'survived',\n",
       "                                                  'age',\n",
       "                                                'sibsp',\n",
       "                                                'parch',\n",
       "                                                 'fare',\n",
       "                                               'female',\n",
       "                                                 'male',\n",
       "                                                    '1',\n",
       "                                                   '10',\n",
       "       ...\n",
       "       'Wimbledon Park, London / Hayling Island, Hants',\n",
       "                        'Windsor, England New York, NY',\n",
       "                                         'Winnipeg, MB',\n",
       "                                         'Winnipeg, MN',\n",
       "                                  'Woodford County, KY',\n",
       "                                   'Worcester, England',\n",
       "                                        'Worcester, MA',\n",
       "                  'Yoevil, England / Cottage Grove, OR',\n",
       "                                       'Youngstown, OH',\n",
       "                                  'Zurich, Switzerland'],\n",
       "      dtype='object', length=718)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/titanic.csv\"\n",
    ")\n",
    "titanic_df = titanic_df.drop(\"name\", axis=1)\n",
    "# catagorical to quantitative\n",
    "catagorical_to_quantitative_maps = {}\n",
    "\n",
    "# gender\n",
    "catagorical_to_quantitative_maps[\"sex\"] = list(titanic_df[\"sex\"].unique())\n",
    "gender_catagories = pd.DataFrame(pd.get_dummies(titanic_df[\"sex\"]))\n",
    "titanic_df = titanic_df.drop(\"sex\", axis = 1)\n",
    "titanic_df= pd.concat([titanic_df, gender_catagories], axis = 1)\n",
    "   \n",
    "# boat\n",
    "titanic_df[\"boat\"] = titanic_df[\"boat\"].fillna(value=\"No boat\")\n",
    "catagorical_to_quantitative_maps[\"boat\"] = list(titanic_df[\"boat\"].unique())\n",
    "boat_catagories = pd.DataFrame(pd.get_dummies(titanic_df[\"boat\"]))\n",
    "titanic_df = titanic_df.drop(\"boat\", axis = 1)\n",
    "titanic_df = pd.concat([titanic_df, boat_catagories], axis = 1)\n",
    "\n",
    "# ticket (idea 1)\n",
    "numeric_tickets = []\n",
    "ticket_letters = {}\n",
    "for ticket in titanic_df[\"ticket\"]:\n",
    "    # if the ticket contains non-numeric characters\n",
    "    if not ticket.isdigit():\n",
    "        # store letters as value with number as key (all tickets have a unique number)\n",
    "        if len(ticket.split(\" \")) > 1:\n",
    "            ticket_letters[ticket.split(\" \")[-1]] = ticket.split(\" \")[:-1]\n",
    "            ticket = (ticket.split(\" \")[-1])\n",
    "        else:\n",
    "            # there is one ticket that just says \"LINE\" whatever that means\n",
    "            ticket_letters[0] = ticket\n",
    "            ticket = 0\n",
    "    numeric_tickets.append(int(ticket))\n",
    "titanic_df = titanic_df.drop(\"ticket\", axis=1)\n",
    "titanic_df = pd.concat([titanic_df, pd.DataFrame({\"ticket\": numeric_tickets})], axis = 1)\n",
    "\n",
    "# ticket (idea 2)\n",
    "# catagorical_to_quantitative_maps[\"ticket\"] = list(titainc_df[\"ticket\"])\n",
    "# tickets = pd.DataFrame(pd.get_dummies(titanic_df[\"ticket\"]))\n",
    "# titanic_df = titanic_df.drop(\"ticket\", axis = 1)\n",
    "# titanic_df = pd.concat([titanic_df, tickets], axis = 1)\n",
    "\n",
    "#cabin\n",
    "catagorical_to_quantitative_maps[\"cabin\"] = list(titanic_df[\"cabin\"].unique())\n",
    "cabins = pd.DataFrame(pd.get_dummies(titanic_df[\"cabin\"]))\n",
    "titanic_df = titanic_df.drop(\"cabin\", axis = 1)\n",
    "titanic_df = pd.concat([titanic_df, cabins], axis = 1)\n",
    "\n",
    "#embarked\n",
    "titanic_df[\"embarked\"] = titanic_df[\"embarked\"].fillna(value=\"entrance unknown\")\n",
    "catagorical_to_quantitative_maps[\"embarked\"] = list(titanic_df[\"embarked\"].unique())\n",
    "entrances = pd.DataFrame(pd.get_dummies(titanic_df[\"embarked\"]))\n",
    "titanic_df = titanic_df.drop(\"embarked\", axis = 1)\n",
    "titanic_df = pd.concat([titanic_df, entrances], axis = 1)\n",
    "\n",
    "\n",
    "#body\n",
    "titanic_df[\"body\"] = titanic_df[\"body\"].fillna(value=\"body unknown\")\n",
    "catagorical_to_quantitative_maps[\"body\"] = list(titanic_df[\"body\"].unique())\n",
    "bodies = pd.DataFrame(pd.get_dummies(titanic_df[\"body\"]))\n",
    "titanic_df = titanic_df.drop(\"body\", axis = 1)\n",
    "titanic_df = pd.concat([titanic_df, bodies], axis = 1)\n",
    "\n",
    "#home.dest\n",
    "catagorical_to_quantitative_maps[\"home.dest\"] = list(titanic_df[\"home.dest\"].unique())\n",
    "destinations = pd.DataFrame(pd.get_dummies(titanic_df[\"home.dest\"]))\n",
    "titanic_df = titanic_df.drop(\"home.dest\", axis = 1)\n",
    "titanic_df = pd.concat([titanic_df, destinations], axis = 1)\n",
    "\n",
    "# #name\n",
    "# catagorical_to_quantitative_maps[\"name\"] = list(titanic_df[\"name\"].unique())\n",
    "# names = pd.DataFrame(pd.get_dummies(titanic_df[\"name\"]))\n",
    "# titanic_df = titanic_df.drop(\"name\", axis = 1)\n",
    "# titanic_df = pd.concat([titanic_df, names], axis = 1)\n",
    "\n",
    "print(titanic_df.shape)\n",
    "\n",
    "# display(titanic_df)\n",
    "# titanic_df.shape\n",
    "\n",
    "for col in titanic_df.columns:\n",
    "    for val in titanic_df[col]:\n",
    "        if type(val) != int and type(val) != float:\n",
    "            print(\"column: \", col)\n",
    "            print(val)\n",
    "            print(\"type: \", type(val))\n",
    "        break\n",
    "#     for element in titanic_df[col].unique():\n",
    "#         if type(element) == str:\n",
    "#             print(\"column: \", col)\n",
    "#             print(\"element: \", element)\n",
    "#             print(\"type: \", type(element))\n",
    "#             break\n",
    "#titanic_df\n",
    "titanic_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
